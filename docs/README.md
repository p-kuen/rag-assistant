# RAG Assistant - Ressourcenoptimierte Fullstack RAG-Plattform

Eine modulare, Docker-basierte RAG (Retrieval-Augmented Generation) Plattform mit VueJS Frontend und Rust Backend.

## ğŸ“ Monorepo-Struktur

```
rag-assistant/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ frontend/              # VueJS Chat & Admin Interface
â”‚   â””â”€â”€ backend-orchestrator/  # Rust Backend fÃ¼r RAG-Pipeline
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ meilisearch/          # Vektor- und Metadaten-Speicher
â”‚   â”œâ”€â”€ embedding-api/        # Text Embeddings Service (TEI)
â”‚   â””â”€â”€ llm-inference/        # LLM Inference Service (llama.cpp)
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml    # Orchestrierung aller Services
â”‚   â”œâ”€â”€ frontend.Dockerfile
â”‚   â”œâ”€â”€ backend.Dockerfile
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md             # Dieser Dokument
â”‚   â”œâ”€â”€ ARCHITECTURE.md       # Architektur-Ãœbersicht
â”‚   â””â”€â”€ DEPLOYMENT.md         # Deployment-Anleitung
â””â”€â”€ pnpm-workspace.yaml       # Pnpm Workspace-Konfiguration
```

## ğŸš€ Schnellstart

### Voraussetzungen

- **Node.js** >= 18.0.0
- **Pnpm** >= 8.0.0
- **Rust** >= 1.75 (fÃ¼r Backend-Entwicklung)
- **Docker** und **Docker Compose**

### 1. Repository klonen und Dependencies installieren

```bash
# Dependencies fÃ¼r alle Workspaces installieren
pnpm install
```

### 2. Docker Services starten

Zuerst mÃ¼ssen Sie ein LLM-Modell herunterladen:

```bash
# Beispiel: Gemma-2-2B quantisiert (Q4_K_M ~1.5GB)
docker run -v rag-assistant_llm-models:/models alpine sh -c \
  "wget https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q4_K_M.gguf -O /models/model.gguf"
```

Dann die Umgebungsvariablen konfigurieren:

```bash
# .env Datei erstellen
cp docker/.env.example docker/.env

# .env bearbeiten und API-Keys setzen
# MEILISEARCH_API_KEY=your_secure_key
```

Alle Services starten:

```bash
# Alle Docker Services starten
pnpm docker:up

# Logs verfolgen
pnpm docker:logs
```

### 3. Frontend Development

```bash
# Frontend im Dev-Modus starten
pnpm dev:frontend

# Oder direkt im Frontend-Ordner
cd apps/frontend
pnpm dev
```

Frontend ist erreichbar unter: http://localhost:5173

### 4. Backend Development

```bash
# Backend im Dev-Modus starten (erfordert cargo-watch)
pnpm dev:backend

# Oder direkt im Backend-Ordner
cd apps/backend-orchestrator
cargo run
```

Backend API ist erreichbar unter: http://localhost:8080

## ğŸ—ï¸ Komponenten-Ãœbersicht

### Frontend (`apps/frontend`)

- **Framework:** VueJS 3 + TypeScript + Vite
- **Styling:** Tailwind CSS v4
- **Routing:** Vue Router
- **Features:**
  - Chat-Assistent Interface (`/chat`)
  - Wissensverwaltung Dashboard (`/admin/knowledge`)
  - Dokument-Upload mit Metadaten
  - Manuelle Markdown-Eingabe
  - Task-Status-Ãœberwachung

### Backend Orchestrator (`apps/backend-orchestrator`)

- **Framework:** Rust (Axum/Actix-web + Tokio)
- **Aufgaben:**
  - RAG-Pipeline Orchestrierung
  - API Gateway fÃ¼r Frontend
  - Koordination zwischen Services
  - Dokument-Chunking und -Processing

**API Endpoints:**
- `GET /health` - Health Check
- `POST /api/chat` - Chat Completions
- `POST /api/documents` - Dokument Upload
- `GET /api/documents` - Dokument Liste

### Meilisearch Service (`services/meilisearch`)

- **Image:** `getmeili/meilisearch:v1.7`
- **Port:** 7700 (intern)
- **Aufgaben:**
  - Vektor- und Keyword-Suche (Hybrid Search)
  - Speicherung von Document Chunks
  - Metadaten-Verwaltung

### Embedding API (`services/embedding-api`)

- **Image:** `ghcr.io/huggingface/text-embeddings-inference:cpu-1.5`
- **Port:** 8080 (intern)
- **Model:** BAAI/bge-small-en-v1.5 (konfigurierbar)
- **API:** OpenAI-kompatibel

### LLM Inference (`services/llm-inference`)

- **Image:** `ghcr.io/ggerganov/llama.cpp:server`
- **Port:** 8080 (intern)
- **Model:** Kompaktes GGUF-Modell (z.B. Gemma-2-2B)
- **API:** OpenAI-kompatibel Chat Completions

## ğŸ”§ VerfÃ¼gbare Scripts

### Root-Level

```bash
# Development
pnpm dev              # Alle Apps im Dev-Modus
pnpm dev:frontend     # Nur Frontend
pnpm dev:backend      # Nur Backend

# Build
pnpm build            # Alle Apps bauen
pnpm build:frontend   # Nur Frontend bauen
pnpm build:backend    # Nur Backend bauen

# Docker
pnpm docker:up        # Docker Services starten
pnpm docker:down      # Docker Services stoppen
pnpm docker:logs      # Docker Logs anzeigen
```

## ğŸ“¦ Ressourcen-Limits

Die Docker-Compose-Konfiguration enthÃ¤lt Ressourcen-Limits fÃ¼r die rechenintensiven Services:

| Service | CPU Limit | Memory Limit | CPU Reservation | Memory Reservation |
|---------|-----------|--------------|-----------------|-------------------|
| Backend | 2.0 | 2GB | 0.5 | 512MB |
| Meilisearch | 2.0 | 4GB | 0.5 | 1GB |
| Embedding API | 2.0 | 4GB | 1.0 | 2GB |
| LLM Inference | 4.0 | 8GB | 2.0 | 4GB |

Diese Limits kÃ¶nnen in `docker/docker-compose.yml` angepasst werden.

## ğŸŒ Service-Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚ :5173 (extern)
â”‚   (VueJS)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend       â”‚ :8080 (extern)
â”‚ Orchestrator    â”‚
â”‚   (Rust)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼    â–¼        â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Meili-  â”‚  â”‚Embeddingâ”‚  â”‚   LLM    â”‚
â”‚search  â”‚  â”‚   API   â”‚  â”‚Inference â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  :7700       :8080         :8080
 (intern)    (intern)      (intern)
```

Alle internen Services kommunizieren Ã¼ber das `rag-net` Docker-Netzwerk.

## ğŸ” Sicherheit

- Interne Services (Meilisearch, Embedding API, LLM) sind **nicht** extern erreichbar
- Nur Frontend und Backend-Orchestrator exponieren externe Ports
- Meilisearch erfordert einen Master Key (in `.env` konfigurieren)
- Docker Container laufen mit non-root User (wo mÃ¶glich)

## ğŸ“š Weitere Dokumentation

- [Architektur-Ãœbersicht](./ARCHITECTURE.md)
- [Deployment-Anleitung](./DEPLOYMENT.md)
- [API-Dokumentation](./API.md)

## ğŸ¤ Beitragen

Da dies ein Monorepo ist, beachten Sie bitte:

1. Alle Packages verwenden Pnpm Workspaces
2. Shared Dependencies sollten im Root `package.json` deklariert werden
3. Service-spezifische Dependencies gehÃ¶ren in die jeweiligen `package.json`
4. Commit-Messages sollten den Workspace-Prefix enthalten (z.B. `[frontend]`, `[backend]`)

## ğŸ“ Lizenz

[Ihre Lizenz hier]
